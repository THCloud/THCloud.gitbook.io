# 搜索

### 常规搜索

query理解：分query纠错，query分词，query归一化，实体识别，意图识别，敏感词识别等

召回：多轮截断

* 李晓娜通过播放量，文档质量等信息计算出文档质量分（L0分），建立倒排链时，会根据L0分进行倒排链的排序。在召回时，一个倒排链下可能有几十万甚至上百万的文档数据，但召回时，只会进行前10w的文档校验（第一次截断）
  * 倒排链的遍历和校验是一个非常耗时的操作，比较常见的思路，第一是减少遍历倒排链的长度，常见的是weak and算法，通过计算每个词的贡献上限来估计文档的相关性上限，从而建立一个阈值对倒排中的结果进行剪枝，从而提速；第二是优化倒排表结果，采用跳表，位图法等加速倒排数据的校验和遍历效率。位图如bitmap和roaring map，前者适合密集id，后者可用于稀疏id
* 校验后得到的文档，会经过相关性分（L1分），topN分（L2分），粗排分，进行相关性截断，topn截断，粗排截断。这些都是在leaf分片进行，最后一个分片只有几百个文档
  * L1分：根据文本相关性进行截断，截断为千量级
  * L2分：根据指定规则，对得到的文档进行排序，获取所需数量文档，变为百量级
  * L3分：根据粗排进行少量截断，变为百量级
* proxy层进行粗排分合并，变成第5次截断，将量级从千量级变为百量级
* policy层根据多召回库进行策略合并，变成第六次截断，最后变为百量级



### Sugg

直达服务向下访问sugg，直达服务有访问直达商业，直达卡的逻辑。

sugg首先进行qu，然后就是召回和排序阶段。召回以前缀召回为主，基本80%以上都是前缀召回词，也有kv召回和分词倒排召回，kv召回有其他引擎的抓取结果，热搜结果等。

前缀召回分proxy，root，leaf三层结构。root层主要为了减少proxy的扇出放大，同时内部有cache逻辑。

* leaf一共41个分片，35E数据，根据queryhash做分片，不支持动态扩缩容
* leaf只有实时写入逻辑，kafka导出时候会同时写离线的全库
* leaf内两个树，原词trie和拼音trie，锁更新，没有01逻辑
* leaf内部有score，qv字段，score为0标记删除。qv是词频；有正排数据，有黄反，作弊分等，用于粗排
* leaf只有写入，标记删除，没有定时重启，会oom；oom后拉取对应的全量库分片，保证数据的更新。每个leaf分set，同set只有一个节点提供服务，一个节点oom了后另一个节点提供服务，继续oom继续重启



### ai，rag

aigc分析意图，携带意图信息到下游搜索系统

搜索正常进行搜索的分词召回，另一路做向量的召回，向量召回为rag。召回的doc会在召回passage信息，即引文，引文跟着离线建库生成。召回后所有的passage会喂给大模型生成对应的总结

plugin信息传递给大模型，大模型的planner可以根据意图决定调用哪些plugin，获取plugin结果，喂给passage
