# 业务

框架部分使用的是上述的图引擎的内容。业务的逻辑大概分如下的流程

* 数据补全：这里做一些正式流程前的处理操作，如实验处理，分词信息处理，画像数据获取等
* 召回：召回按照大体的介质和方式分为几类：
  * kv类型召回，使用到底层存储为sos
  * 倒排类召回，用上面的分词做召回，用搜索中台的能力
  * ann向量类召回，使用推荐中台能力
  * gnn召回，图类型的召回，使用推荐中台能力
  * llm近线召回，大模型类的召回
* 粗排：服务规模小做本地的粗排，128维向量，输入均值大概1000，输出不到400
* 特征获取：拿到对应的统计特征信息，如pv，ctr，黄反造谣质量分等信息
* 排序：进行特征组织和打分的过程。输出三种分，ctr分，商业分，sess满意度分
* 混排：三种分进行混合排序，最后也会进行一些产品运营维度上的特殊调整操作
* 回包：返回最后结果，同时上报中间处理过程，包括召回了哪些，打分了哪些出了哪些，这些都作为模型训练样板会喂给模型



一些问题

* 模型训练时候如何保证线上效果或者上线不出大波动问题
  * 上线前有测试环境，测试环境跟线上环境做对比，回放线上抽样的流量拿到最后的推荐结果，最后做结果的gsb自评，g good s same b bad对比模型上线的效果。gsb效果不行需要再调整
  * 上线前有diff测试的流水线环节，正常来说因为推荐自身本身有随机性，aa的diff率在千分之6以内，所以模型修改后diff率超过了这个值，需要先自查是否符合预期才能上线
  * 上线后有点爆监控，模型的上线会根据实验和分级上线来逐步放量，根据对应点爆监控观察数据效果。如果波动较大，需要回滚排查
* 模型a实验没有问题，模型b实验没有问题，但是两个模型同时上有问题，如何确认这种问题
  * 线上有一种长期反转桶机制，专门用于多模型累计效果的对比。多个模型用的反转桶是同一个桶，具体反转桶原理不太清楚



稳定性

稳定性建设需要看线上问题的原因，做最后的规划建设，一般分为以下几个阶段和建设的落地步骤f

* 发布前：代码规范，一级流水线等
  * 代码必须合并master然后发布，禁止分支发布；必须master打tag发布
  * 代码规范要过，单测要求增量覆盖率超过60%，用例通过率100%
* 上线前：
  * 多级流水线，稳定性测试，接口测试，性能测试，diff率测试
  * 上线班车机制：一天一趟上线，合并发布
* 上线中：
  * 分级发布，发单台观察/多地单台观察/单地10%/多地10%/单地推全/多地推全
  * 分级发布过程强制停留观察15分钟，观察checklist，包括cpu/耗时/有结果率/ctr等其他效果指标等
* 告警
